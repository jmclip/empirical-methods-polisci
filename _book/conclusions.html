<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>25 Conclusions | Empirical Methods in Political Science: An Introduction</title>
  <meta name="description" content="This is an introductory college textbook on using empirical methods in political science research." />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="25 Conclusions | Empirical Methods in Political Science: An Introduction" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an introductory college textbook on using empirical methods in political science research." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="25 Conclusions | Empirical Methods in Political Science: An Introduction" />
  
  <meta name="twitter:description" content="This is an introductory college textbook on using empirical methods in political science research." />
  

<meta name="author" content="Jean Clipperton" />


<meta name="date" content="2020-02-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="machine-learning.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Empirical Methods in Political Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html"><i class="fa fa-check"></i><b>1</b> Introduction: What is political science?</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html#subfields-in-political-science"><i class="fa fa-check"></i><b>1.1</b> Subfields in Political Science</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html#questions-in-political-science"><i class="fa fa-check"></i><b>1.2</b> Questions in Political Science</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html#what-are-empirical-political-science-methods"><i class="fa fa-check"></i><b>1.3</b> What are Empirical Political Science Methods?</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html#types-of-methods"><i class="fa fa-check"></i><b>1.3.1</b> Types of Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html#scientific-method"><i class="fa fa-check"></i><b>1.4</b> Scientific Method</a></li>
<li class="chapter" data-level="1.5" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html#what-can-research-tell-us"><i class="fa fa-check"></i><b>1.5</b> What can Research Tell us?</a><ul>
<li class="chapter" data-level="1.5.1" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html#support-for-hypotheses"><i class="fa fa-check"></i><b>1.5.1</b> Support for hypotheses</a></li>
<li class="chapter" data-level="1.5.2" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html#generalizability"><i class="fa fa-check"></i><b>1.5.2</b> Generalizability</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction-what-is-political-science.html"><a href="introduction-what-is-political-science.html#overview-of-textbook"><i class="fa fa-check"></i><b>1.6</b> Overview of textbook</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="causal-inference-and-the-scientific-method.html"><a href="causal-inference-and-the-scientific-method.html"><i class="fa fa-check"></i><b>2</b> Causal Inference and the Scientific Method</a><ul>
<li class="chapter" data-level="2.1" data-path="causal-inference-and-the-scientific-method.html"><a href="causal-inference-and-the-scientific-method.html#introductionbackground"><i class="fa fa-check"></i><b>2.1</b> Introduction/Background</a></li>
<li class="chapter" data-level="2.2" data-path="causal-inference-and-the-scientific-method.html"><a href="causal-inference-and-the-scientific-method.html#setup-the-scientific-method"><i class="fa fa-check"></i><b>2.2</b> Setup: The scientific Method</a></li>
<li class="chapter" data-level="2.3" data-path="causal-inference-and-the-scientific-method.html"><a href="causal-inference-and-the-scientific-method.html#the-fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>2.3</b> The Fundamental Problem of Causal Inference</a></li>
<li class="chapter" data-level="2.4" data-path="causal-inference-and-the-scientific-method.html"><a href="causal-inference-and-the-scientific-method.html#conclusion"><i class="fa fa-check"></i><b>2.4</b> Conclusion</a></li>
<li class="chapter" data-level="2.5" data-path="causal-inference-and-the-scientific-method.html"><a href="causal-inference-and-the-scientific-method.html#application-questions"><i class="fa fa-check"></i><b>2.5</b> Application Questions</a></li>
<li class="chapter" data-level="2.6" data-path="causal-inference-and-the-scientific-method.html"><a href="causal-inference-and-the-scientific-method.html#key-terms"><i class="fa fa-check"></i><b>2.6</b> Key Terms</a><ul>
<li class="chapter" data-level="2.6.1" data-path="causal-inference-and-the-scientific-method.html"><a href="causal-inference-and-the-scientific-method.html#answers-to-check-in-questions"><i class="fa fa-check"></i><b>2.6.1</b> Answers to Check-in Questions</a></li>
<li class="chapter" data-level="2.6.2" data-path="causal-inference-and-the-scientific-method.html"><a href="causal-inference-and-the-scientific-method.html#answers-to-application-questions"><i class="fa fa-check"></i><b>2.6.2</b> Answers to Application Questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theory</a><ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#what-is-a-theory"><i class="fa fa-check"></i><b>3.2</b> What is a theory?</a></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#what-is-a-good-theory"><i class="fa fa-check"></i><b>3.3</b> What is a <em>good</em> theory?</a></li>
<li class="chapter" data-level="3.4" data-path="theory.html"><a href="theory.html#literature-reviews-and-theory"><i class="fa fa-check"></i><b>3.4</b> Literature Reviews and Theory</a></li>
<li class="chapter" data-level="3.5" data-path="theory.html"><a href="theory.html#conclusion-1"><i class="fa fa-check"></i><b>3.5</b> Conclusion</a></li>
<li class="chapter" data-level="3.6" data-path="theory.html"><a href="theory.html#application-questions-1"><i class="fa fa-check"></i><b>3.6</b> Application Questions</a></li>
<li class="chapter" data-level="3.7" data-path="theory.html"><a href="theory.html#key-terms-1"><i class="fa fa-check"></i><b>3.7</b> Key Terms</a></li>
<li class="chapter" data-level="3.8" data-path="theory.html"><a href="theory.html#answers-to-application-questions-1"><i class="fa fa-check"></i><b>3.8</b> Answers to Application Questions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>4</b> Data</a><ul>
<li class="chapter" data-level="4.1" data-path="data.html"><a href="data.html#introduction-1"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="data.html"><a href="data.html#types-of-variables"><i class="fa fa-check"></i><b>4.2</b> Types of Variables</a></li>
<li class="chapter" data-level="4.3" data-path="data.html"><a href="data.html#types-of-data"><i class="fa fa-check"></i><b>4.3</b> Types of Data</a></li>
<li class="chapter" data-level="4.4" data-path="data.html"><a href="data.html#samples-and-sampling"><i class="fa fa-check"></i><b>4.4</b> Samples and Sampling</a></li>
<li class="chapter" data-level="4.5" data-path="data.html"><a href="data.html#measurement"><i class="fa fa-check"></i><b>4.5</b> Measurement</a></li>
<li class="chapter" data-level="4.6" data-path="data.html"><a href="data.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>4.6</b> Measures of Central Tendency</a></li>
<li class="chapter" data-level="4.7" data-path="data.html"><a href="data.html#broader-significanceuse-in-political-science"><i class="fa fa-check"></i><b>4.7</b> Broader significance/use in political science</a></li>
<li class="chapter" data-level="4.8" data-path="data.html"><a href="data.html#conclusion-2"><i class="fa fa-check"></i><b>4.8</b> Conclusion</a></li>
<li class="chapter" data-level="4.9" data-path="data.html"><a href="data.html#application-questions-2"><i class="fa fa-check"></i><b>4.9</b> Application Questions</a></li>
<li class="chapter" data-level="4.10" data-path="data.html"><a href="data.html#key-terms-2"><i class="fa fa-check"></i><b>4.10</b> Key Terms</a></li>
<li class="chapter" data-level="4.11" data-path="data.html"><a href="data.html#answers-to-application-questions-2"><i class="fa fa-check"></i><b>4.11</b> Answers to Application Questions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis.html"><a href="hypothesis.html"><i class="fa fa-check"></i><b>5</b> Hypothesis</a><ul>
<li class="chapter" data-level="5.1" data-path="hypothesis.html"><a href="hypothesis.html#introduction-2"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="hypothesis.html"><a href="hypothesis.html#background"><i class="fa fa-check"></i><b>5.2</b> Background</a></li>
<li class="chapter" data-level="5.3" data-path="hypothesis.html"><a href="hypothesis.html#samples-and-sampling-1"><i class="fa fa-check"></i><b>5.3</b> Samples and Sampling</a><ul>
<li class="chapter" data-level="5.3.1" data-path="hypothesis.html"><a href="hypothesis.html#magic-of-the-central-limit-theorem"><i class="fa fa-check"></i><b>5.3.1</b> Magic of the Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="hypothesis.html"><a href="hypothesis.html#estimates-and-certainty"><i class="fa fa-check"></i><b>5.4</b> Estimates and Certainty</a></li>
<li class="chapter" data-level="5.5" data-path="hypothesis.html"><a href="hypothesis.html#steps-of-hypothesis-testing"><i class="fa fa-check"></i><b>5.5</b> Steps of Hypothesis Testing</a></li>
<li class="chapter" data-level="5.6" data-path="hypothesis.html"><a href="hypothesis.html#types-of-hypothesis-testing"><i class="fa fa-check"></i><b>5.6</b> Types of Hypothesis testing</a><ul>
<li class="chapter" data-level="5.6.1" data-path="hypothesis.html"><a href="hypothesis.html#single-mean-hypothesis-testing"><i class="fa fa-check"></i><b>5.6.1</b> Single Mean Hypothesis Testing</a></li>
<li class="chapter" data-level="5.6.2" data-path="hypothesis.html"><a href="hypothesis.html#difference-of-means-hypothesis-testing"><i class="fa fa-check"></i><b>5.6.2</b> Difference of Means Hypothesis Testing</a></li>
<li class="chapter" data-level="5.6.3" data-path="hypothesis.html"><a href="hypothesis.html#regression-coefficients-hypothesis-testing"><i class="fa fa-check"></i><b>5.6.3</b> Regression Coefficients Hypothesis Testing</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="hypothesis.html"><a href="hypothesis.html#conclusions-you-can-draw-based-on-the-type-of-test"><i class="fa fa-check"></i><b>5.7</b> Conclusions you can draw based on the type of test</a></li>
<li class="chapter" data-level="5.8" data-path="hypothesis.html"><a href="hypothesis.html#applications"><i class="fa fa-check"></i><b>5.8</b> Applications</a></li>
<li class="chapter" data-level="5.9" data-path="hypothesis.html"><a href="hypothesis.html#is-it-weird"><i class="fa fa-check"></i><b>5.9</b> “Is it weird?”</a></li>
<li class="chapter" data-level="5.10" data-path="hypothesis.html"><a href="hypothesis.html#broader-significanceuse-in-political-science-1"><i class="fa fa-check"></i><b>5.10</b> Broader significance/use in political science</a></li>
<li class="chapter" data-level="5.11" data-path="hypothesis.html"><a href="hypothesis.html#conclusion-3"><i class="fa fa-check"></i><b>5.11</b> Conclusion</a></li>
<li class="chapter" data-level="5.12" data-path="hypothesis.html"><a href="hypothesis.html#application-questions-3"><i class="fa fa-check"></i><b>5.12</b> Application Questions</a></li>
<li class="chapter" data-level="5.13" data-path="hypothesis.html"><a href="hypothesis.html#key-terms-3"><i class="fa fa-check"></i><b>5.13</b> Key Terms</a></li>
<li class="chapter" data-level="5.14" data-path="hypothesis.html"><a href="hypothesis.html#answers-to-application-questions-3"><i class="fa fa-check"></i><b>5.14</b> Answers to Application Questions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="surveys.html"><a href="surveys.html"><i class="fa fa-check"></i><b>6</b> Surveys</a><ul>
<li class="chapter" data-level="6.1" data-path="surveys.html"><a href="surveys.html#introduction-background"><i class="fa fa-check"></i><b>6.1</b> Introduction &amp; Background</a></li>
<li class="chapter" data-level="6.2" data-path="surveys.html"><a href="surveys.html#brief-history-of-survey-research"><i class="fa fa-check"></i><b>6.2</b> Brief History of Survey Research</a></li>
<li class="chapter" data-level="6.3" data-path="surveys.html"><a href="surveys.html#designing-a-survey-research"><i class="fa fa-check"></i><b>6.3</b> Designing a Survey Research</a></li>
<li class="chapter" data-level="6.4" data-path="surveys.html"><a href="surveys.html#applications-1"><i class="fa fa-check"></i><b>6.4</b> Applications</a></li>
<li class="chapter" data-level="6.5" data-path="surveys.html"><a href="surveys.html#advantages-of-method"><i class="fa fa-check"></i><b>6.5</b> Advantages of Method</a></li>
<li class="chapter" data-level="6.6" data-path="surveys.html"><a href="surveys.html#disadvantages-of-method-surveys-easier-said-than-done"><i class="fa fa-check"></i><b>6.6</b> Disadvantages of Method: Surveys, Easier Said than Done</a></li>
<li class="chapter" data-level="6.7" data-path="surveys.html"><a href="surveys.html#broader-significanceuse-in-political-science-2"><i class="fa fa-check"></i><b>6.7</b> Broader significance/use in political science</a></li>
<li class="chapter" data-level="6.8" data-path="surveys.html"><a href="surveys.html#conclusion-4"><i class="fa fa-check"></i><b>6.8</b> Conclusion</a></li>
<li class="chapter" data-level="6.9" data-path="surveys.html"><a href="surveys.html#application-questions-4"><i class="fa fa-check"></i><b>6.9</b> Application Questions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="key-terms-4.html"><a href="key-terms-4.html"><i class="fa fa-check"></i><b>7</b> Key Terms</a><ul>
<li class="chapter" data-level="7.1" data-path="key-terms-4.html"><a href="key-terms-4.html#answers-to-application-questions-4"><i class="fa fa-check"></i><b>7.1</b> Answers to Application Questions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="experiments.html"><a href="experiments.html"><i class="fa fa-check"></i><b>8</b> Experiments</a><ul>
<li class="chapter" data-level="8.1" data-path="experiments.html"><a href="experiments.html#introduction-3"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="experiments.html"><a href="experiments.html#background-1"><i class="fa fa-check"></i><b>8.2</b> Background</a></li>
<li class="chapter" data-level="8.3" data-path="experiments.html"><a href="experiments.html#method-setupoverview"><i class="fa fa-check"></i><b>8.3</b> Method: setup/overview</a><ul>
<li class="chapter" data-level="8.3.1" data-path="experiments.html"><a href="experiments.html#check-in-question-1"><i class="fa fa-check"></i><b>8.3.1</b> Check-in Question 1</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="experiments.html"><a href="experiments.html#method-detail-types-of-experiments"><i class="fa fa-check"></i><b>8.4</b> Method: detail (types of experiments)</a><ul>
<li class="chapter" data-level="8.4.1" data-path="experiments.html"><a href="experiments.html#surveys-vs-survey-experiments"><i class="fa fa-check"></i><b>8.4.1</b> Surveys vs Survey Experiments</a></li>
<li class="chapter" data-level="8.4.2" data-path="experiments.html"><a href="experiments.html#laboratory-experiments"><i class="fa fa-check"></i><b>8.4.2</b> Laboratory Experiments</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="experiments.html"><a href="experiments.html#check-in-question-2"><i class="fa fa-check"></i><b>8.5</b> Check-in Question 2</a></li>
<li class="chapter" data-level="8.6" data-path="experiments.html"><a href="experiments.html#field-experiments"><i class="fa fa-check"></i><b>8.6</b> Field Experiments</a></li>
<li class="chapter" data-level="8.7" data-path="experiments.html"><a href="experiments.html#natural-experiments"><i class="fa fa-check"></i><b>8.7</b> Natural Experiments</a></li>
<li class="chapter" data-level="8.8" data-path="experiments.html"><a href="experiments.html#advantages-of-method-1"><i class="fa fa-check"></i><b>8.8</b> Advantages of Method</a></li>
<li class="chapter" data-level="8.9" data-path="experiments.html"><a href="experiments.html#disadvantages-of-method"><i class="fa fa-check"></i><b>8.9</b> Disadvantages of Method</a></li>
<li class="chapter" data-level="8.10" data-path="experiments.html"><a href="experiments.html#broader-significanceuse-in-political-science-3"><i class="fa fa-check"></i><b>8.10</b> Broader significance/use in political science</a></li>
<li class="chapter" data-level="8.11" data-path="experiments.html"><a href="experiments.html#conclusion-5"><i class="fa fa-check"></i><b>8.11</b> Conclusion</a></li>
<li class="chapter" data-level="8.12" data-path="experiments.html"><a href="experiments.html#application-questions-5"><i class="fa fa-check"></i><b>8.12</b> Application Questions</a><ul>
<li class="chapter" data-level="8.12.1" data-path="experiments.html"><a href="experiments.html#application-question-1"><i class="fa fa-check"></i><b>8.12.1</b> Application Question 1</a></li>
<li class="chapter" data-level="8.12.2" data-path="experiments.html"><a href="experiments.html#application-question-2"><i class="fa fa-check"></i><b>8.12.2</b> Application Question 2</a></li>
</ul></li>
<li class="chapter" data-level="8.13" data-path="experiments.html"><a href="experiments.html#key-terms-5"><i class="fa fa-check"></i><b>8.13</b> Key Terms</a></li>
<li class="chapter" data-level="8.14" data-path="experiments.html"><a href="experiments.html#answers-to-application-questions-5"><i class="fa fa-check"></i><b>8.14</b> Answers to Application Questions</a></li>
<li class="chapter" data-level="8.15" data-path="experiments.html"><a href="experiments.html#answer-1"><i class="fa fa-check"></i><b>8.15</b> Answer 1</a></li>
<li class="chapter" data-level="8.16" data-path="experiments.html"><a href="experiments.html#answer-2"><i class="fa fa-check"></i><b>8.16</b> Answer 2</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="large-n.html"><a href="large-n.html"><i class="fa fa-check"></i><b>9</b> Large N</a><ul>
<li class="chapter" data-level="9.1" data-path="large-n.html"><a href="large-n.html#introduction-4"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="large-n.html"><a href="large-n.html#method-setupoverview-1"><i class="fa fa-check"></i><b>9.2</b> Method: setup/overview</a><ul>
<li class="chapter" data-level="9.2.1" data-path="large-n.html"><a href="large-n.html#correlation"><i class="fa fa-check"></i><b>9.2.1</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="large-n.html"><a href="large-n.html#regression"><i class="fa fa-check"></i><b>9.3</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="method-detail.html"><a href="method-detail.html"><i class="fa fa-check"></i><b>10</b> Method: detail</a><ul>
<li class="chapter" data-level="10.1" data-path="method-detail.html"><a href="method-detail.html#finding-the-line-of-best-fit"><i class="fa fa-check"></i><b>10.1</b> Finding the Line of Best Fit</a></li>
<li class="chapter" data-level="10.2" data-path="method-detail.html"><a href="method-detail.html#significance-tests"><i class="fa fa-check"></i><b>10.2</b> Significance Tests</a></li>
<li class="chapter" data-level="10.3" data-path="method-detail.html"><a href="method-detail.html#multivariate-regression"><i class="fa fa-check"></i><b>10.3</b> Multivariate Regression</a></li>
<li class="chapter" data-level="10.4" data-path="method-detail.html"><a href="method-detail.html#reading-a-regression-table"><i class="fa fa-check"></i><b>10.4</b> Reading a Regression Table</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="applications-2.html"><a href="applications-2.html"><i class="fa fa-check"></i><b>11</b> Applications</a><ul>
<li class="chapter" data-level="11.1" data-path="applications-2.html"><a href="applications-2.html#correlation-1"><i class="fa fa-check"></i><b>11.1</b> Correlation</a></li>
<li class="chapter" data-level="11.2" data-path="applications-2.html"><a href="applications-2.html#regression-1"><i class="fa fa-check"></i><b>11.2</b> Regression</a></li>
<li class="chapter" data-level="11.3" data-path="applications-2.html"><a href="applications-2.html#logistic-regression"><i class="fa fa-check"></i><b>11.3</b> Logistic Regression</a></li>
<li class="chapter" data-level="11.4" data-path="applications-2.html"><a href="applications-2.html#experiments-1"><i class="fa fa-check"></i><b>11.4</b> Experiments</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="advantages-of-method-2.html"><a href="advantages-of-method-2.html"><i class="fa fa-check"></i><b>12</b> Advantages of Method</a></li>
<li class="chapter" data-level="13" data-path="limitations-of-method.html"><a href="limitations-of-method.html"><i class="fa fa-check"></i><b>13</b> Limitations of Method</a></li>
<li class="chapter" data-level="14" data-path="broader-significance-in-political-science.html"><a href="broader-significance-in-political-science.html"><i class="fa fa-check"></i><b>14</b> Broader significance in political science</a></li>
<li class="chapter" data-level="15" data-path="application-questions-6.html"><a href="application-questions-6.html"><i class="fa fa-check"></i><b>15</b> Application Questions</a></li>
<li class="chapter" data-level="16" data-path="key-terms-6.html"><a href="key-terms-6.html"><i class="fa fa-check"></i><b>16</b> Key Terms</a></li>
<li class="chapter" data-level="17" data-path="answers-to-application-questions-6.html"><a href="answers-to-application-questions-6.html"><i class="fa fa-check"></i><b>17</b> Answers to Application Questions</a><ul>
<li class="chapter" data-level="17.1" data-path="answers-to-application-questions-6.html"><a href="answers-to-application-questions-6.html#check-in-questions"><i class="fa fa-check"></i><b>17.1</b> Check-in Questions</a></li>
<li class="chapter" data-level="17.2" data-path="answers-to-application-questions-6.html"><a href="answers-to-application-questions-6.html#application-questions-7"><i class="fa fa-check"></i><b>17.2</b> Application Questions</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="math-appendix.html"><a href="math-appendix.html"><i class="fa fa-check"></i><b>18</b> Mathematical Appendix</a><ul>
<li class="chapter" data-level="18.1" data-path="math-appendix.html"><a href="math-appendix.html#calculating-the-regression-coefficient"><i class="fa fa-check"></i><b>18.1</b> Calculating the Regression Coefficient</a></li>
<li class="chapter" data-level="18.2" data-path="math-appendix.html"><a href="math-appendix.html#significance-tests-1"><i class="fa fa-check"></i><b>18.2</b> Significance Tests</a></li>
<li class="chapter" data-level="18.3" data-path="math-appendix.html"><a href="math-appendix.html#error-terms"><i class="fa fa-check"></i><b>18.3</b> Error Terms</a></li>
<li class="chapter" data-level="18.4" data-path="math-appendix.html"><a href="math-appendix.html#logged-variables"><i class="fa fa-check"></i><b>18.4</b> Logged Variables</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="small-n.html"><a href="small-n.html"><i class="fa fa-check"></i><b>19</b> Small N</a><ul>
<li class="chapter" data-level="19.1" data-path="small-n.html"><a href="small-n.html#introduction-5"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="small-n.html"><a href="small-n.html#background-2"><i class="fa fa-check"></i><b>19.2</b> Background</a></li>
<li class="chapter" data-level="19.3" data-path="small-n.html"><a href="small-n.html#case-selection"><i class="fa fa-check"></i><b>19.3</b> Case Selection</a><ul>
<li class="chapter" data-level="19.3.1" data-path="small-n.html"><a href="small-n.html#most-similar"><i class="fa fa-check"></i><b>19.3.1</b> Most Similar</a></li>
<li class="chapter" data-level="19.3.2" data-path="small-n.html"><a href="small-n.html#most-different"><i class="fa fa-check"></i><b>19.3.2</b> Most Different</a></li>
<li class="chapter" data-level="19.3.3" data-path="small-n.html"><a href="small-n.html#typical-case"><i class="fa fa-check"></i><b>19.3.3</b> Typical Case</a></li>
<li class="chapter" data-level="19.3.4" data-path="small-n.html"><a href="small-n.html#deviant-case"><i class="fa fa-check"></i><b>19.3.4</b> Deviant Case</a></li>
<li class="chapter" data-level="19.3.5" data-path="small-n.html"><a href="small-n.html#other-selection-approaches"><i class="fa fa-check"></i><b>19.3.5</b> Other Selection Approaches</a></li>
<li class="chapter" data-level="19.3.6" data-path="small-n.html"><a href="small-n.html#check-in-question-1-1"><i class="fa fa-check"></i><b>19.3.6</b> Check-in Question 1</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="small-n.html"><a href="small-n.html#method-setupoverview-2"><i class="fa fa-check"></i><b>19.4</b> Method: setup/overview</a></li>
<li class="chapter" data-level="19.5" data-path="small-n.html"><a href="small-n.html#method-types"><i class="fa fa-check"></i><b>19.5</b> Method: types</a><ul>
<li class="chapter" data-level="19.5.1" data-path="small-n.html"><a href="small-n.html#interviews"><i class="fa fa-check"></i><b>19.5.1</b> Interviews</a></li>
<li class="chapter" data-level="19.5.2" data-path="small-n.html"><a href="small-n.html#check-in-question-2-1"><i class="fa fa-check"></i><b>19.5.2</b> Check-in Question 2</a></li>
<li class="chapter" data-level="19.5.3" data-path="small-n.html"><a href="small-n.html#participant-observation"><i class="fa fa-check"></i><b>19.5.3</b> Participant Observation</a></li>
<li class="chapter" data-level="19.5.4" data-path="small-n.html"><a href="small-n.html#check-in-question-3"><i class="fa fa-check"></i><b>19.5.4</b> Check-in Question 3</a></li>
<li class="chapter" data-level="19.5.5" data-path="small-n.html"><a href="small-n.html#focus-groups"><i class="fa fa-check"></i><b>19.5.5</b> Focus Groups</a></li>
<li class="chapter" data-level="19.5.6" data-path="small-n.html"><a href="small-n.html#process-tracing"><i class="fa fa-check"></i><b>19.5.6</b> Process Tracing</a></li>
<li class="chapter" data-level="19.5.7" data-path="small-n.html"><a href="small-n.html#ethnography"><i class="fa fa-check"></i><b>19.5.7</b> Ethnography</a></li>
<li class="chapter" data-level="19.5.8" data-path="small-n.html"><a href="small-n.html#check-in-question-4"><i class="fa fa-check"></i><b>19.5.8</b> Check-in Question 4</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="small-n.html"><a href="small-n.html#applications-3"><i class="fa fa-check"></i><b>19.6</b> Applications</a></li>
<li class="chapter" data-level="19.7" data-path="small-n.html"><a href="small-n.html#advantages-of-method-3"><i class="fa fa-check"></i><b>19.7</b> Advantages of Method</a></li>
<li class="chapter" data-level="19.8" data-path="small-n.html"><a href="small-n.html#disadvantages-of-method-1"><i class="fa fa-check"></i><b>19.8</b> Disadvantages of Method</a></li>
<li class="chapter" data-level="19.9" data-path="small-n.html"><a href="small-n.html#broader-significanceuse-in-political-science-4"><i class="fa fa-check"></i><b>19.9</b> Broader significance/use in political science</a></li>
<li class="chapter" data-level="19.10" data-path="small-n.html"><a href="small-n.html#conclusion-6"><i class="fa fa-check"></i><b>19.10</b> Conclusion</a></li>
<li class="chapter" data-level="19.11" data-path="small-n.html"><a href="small-n.html#application-questions-8"><i class="fa fa-check"></i><b>19.11</b> Application Questions</a></li>
<li class="chapter" data-level="19.12" data-path="small-n.html"><a href="small-n.html#application-question-1-1"><i class="fa fa-check"></i><b>19.12</b> Application Question 1</a></li>
<li class="chapter" data-level="19.13" data-path="small-n.html"><a href="small-n.html#application-question-2-1"><i class="fa fa-check"></i><b>19.13</b> Application Question 2</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="key-terms-7.html"><a href="key-terms-7.html"><i class="fa fa-check"></i><b>20</b> Key Terms</a></li>
<li class="chapter" data-level="21" data-path="answers-to-application-questions-7.html"><a href="answers-to-application-questions-7.html"><i class="fa fa-check"></i><b>21</b> Answers to Application Questions</a><ul>
<li class="chapter" data-level="21.1" data-path="answers-to-application-questions-7.html"><a href="answers-to-application-questions-7.html#answer-1-1"><i class="fa fa-check"></i><b>21.1</b> Answer 1</a></li>
<li class="chapter" data-level="21.2" data-path="answers-to-application-questions-7.html"><a href="answers-to-application-questions-7.html#answer-2-1"><i class="fa fa-check"></i><b>21.2</b> Answer 2</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="manual-bibliography-delete-after-checking.html"><a href="manual-bibliography-delete-after-checking.html"><i class="fa fa-check"></i><b>22</b> Manual Bibliography - delete after checking</a></li>
<li class="chapter" data-level="23" data-path="game-theory.html"><a href="game-theory.html"><i class="fa fa-check"></i><b>23</b> Game Theory</a><ul>
<li class="chapter" data-level="23.1" data-path="game-theory.html"><a href="game-theory.html#introduction-6"><i class="fa fa-check"></i><b>23.1</b> Introduction</a></li>
<li class="chapter" data-level="23.2" data-path="game-theory.html"><a href="game-theory.html#background-3"><i class="fa fa-check"></i><b>23.2</b> Background</a></li>
<li class="chapter" data-level="23.3" data-path="game-theory.html"><a href="game-theory.html#method-setupoverview-3"><i class="fa fa-check"></i><b>23.3</b> Method: setup/overview</a></li>
<li class="chapter" data-level="23.4" data-path="game-theory.html"><a href="game-theory.html#method-detail-1"><i class="fa fa-check"></i><b>23.4</b> Method: detail</a></li>
<li class="chapter" data-level="23.5" data-path="game-theory.html"><a href="game-theory.html#applications-4"><i class="fa fa-check"></i><b>23.5</b> Applications</a></li>
<li class="chapter" data-level="23.6" data-path="game-theory.html"><a href="game-theory.html#advantages-of-method-4"><i class="fa fa-check"></i><b>23.6</b> Advantages of Method</a></li>
<li class="chapter" data-level="23.7" data-path="game-theory.html"><a href="game-theory.html#disadvantages-of-method-2"><i class="fa fa-check"></i><b>23.7</b> Disadvantages of Method</a></li>
<li class="chapter" data-level="23.8" data-path="game-theory.html"><a href="game-theory.html#broader-significanceuse-in-political-science-5"><i class="fa fa-check"></i><b>23.8</b> Broader significance/use in political science</a></li>
<li class="chapter" data-level="23.9" data-path="game-theory.html"><a href="game-theory.html#conclusion-7"><i class="fa fa-check"></i><b>23.9</b> Conclusion</a></li>
<li class="chapter" data-level="23.10" data-path="game-theory.html"><a href="game-theory.html#application-questions-9"><i class="fa fa-check"></i><b>23.10</b> Application Questions</a></li>
<li class="chapter" data-level="23.11" data-path="game-theory.html"><a href="game-theory.html#key-terms-8"><i class="fa fa-check"></i><b>23.11</b> Key Terms</a></li>
<li class="chapter" data-level="23.12" data-path="game-theory.html"><a href="game-theory.html#answers-to-application-questions-8"><i class="fa fa-check"></i><b>23.12</b> Answers to Application Questions</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>24</b> Machine Learning</a><ul>
<li class="chapter" data-level="24.1" data-path="machine-learning.html"><a href="machine-learning.html#introduction-7"><i class="fa fa-check"></i><b>24.1</b> Introduction</a></li>
<li class="chapter" data-level="24.2" data-path="machine-learning.html"><a href="machine-learning.html#background-4"><i class="fa fa-check"></i><b>24.2</b> Background</a><ul>
<li class="chapter" data-level="24.2.1" data-path="machine-learning.html"><a href="machine-learning.html#a-brief-note-on-notation"><i class="fa fa-check"></i><b>24.2.1</b> A Brief Note on Notation</a></li>
<li class="chapter" data-level="24.2.2" data-path="machine-learning.html"><a href="machine-learning.html#the-structure-of-prediction-error"><i class="fa fa-check"></i><b>24.2.2</b> The Structure of Prediction Error</a></li>
<li class="chapter" data-level="24.2.3" data-path="machine-learning.html"><a href="machine-learning.html#bias-variance-trade-offs"><i class="fa fa-check"></i><b>24.2.3</b> Bias-Variance Trade-offs</a></li>
<li class="chapter" data-level="24.2.4" data-path="machine-learning.html"><a href="machine-learning.html#parametric-v.-non-parametric-methods"><i class="fa fa-check"></i><b>24.2.4</b> Parametric v. Non-parametric Methods</a></li>
<li class="chapter" data-level="24.2.5" data-path="machine-learning.html"><a href="machine-learning.html#supervised-v.-unsupervised-learning"><i class="fa fa-check"></i><b>24.2.5</b> Supervised v. Unsupervised Learning</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="machine-learning.html"><a href="machine-learning.html#method-setupoverview-4"><i class="fa fa-check"></i><b>24.3</b> Method: setup/overview</a><ul>
<li class="chapter" data-level="24.3.1" data-path="machine-learning.html"><a href="machine-learning.html#what-is-model-selection"><i class="fa fa-check"></i><b>24.3.1</b> What is Model Selection?</a></li>
<li class="chapter" data-level="24.3.2" data-path="machine-learning.html"><a href="machine-learning.html#why-k-fold-cross-validation"><i class="fa fa-check"></i><b>24.3.2</b> Why K-Fold Cross-Validation?</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="machine-learning.html"><a href="machine-learning.html#method-detail-2"><i class="fa fa-check"></i><b>24.4</b> Method: detail</a><ul>
<li class="chapter" data-level="24.4.1" data-path="machine-learning.html"><a href="machine-learning.html#model-class-tree-based-methods"><i class="fa fa-check"></i><b>24.4.1</b> Model Class: Tree-based Methods</a></li>
<li class="chapter" data-level="24.4.2" data-path="machine-learning.html"><a href="machine-learning.html#model-class-support-vector-machines"><i class="fa fa-check"></i><b>24.4.2</b> Model Class: Support Vector Machines</a></li>
</ul></li>
<li class="chapter" data-level="24.5" data-path="machine-learning.html"><a href="machine-learning.html#applications-5"><i class="fa fa-check"></i><b>24.5</b> Applications</a><ul>
<li class="chapter" data-level="24.5.1" data-path="machine-learning.html"><a href="machine-learning.html#example-1-u.s.-politics"><i class="fa fa-check"></i><b>24.5.1</b> Example 1: U.S. Politics</a></li>
<li class="chapter" data-level="24.5.2" data-path="machine-learning.html"><a href="machine-learning.html#example-2-comparative-politics"><i class="fa fa-check"></i><b>24.5.2</b> Example 2: Comparative Politics</a></li>
<li class="chapter" data-level="24.5.3" data-path="machine-learning.html"><a href="machine-learning.html#example-3-political-theory"><i class="fa fa-check"></i><b>24.5.3</b> Example 3: Political Theory</a></li>
<li class="chapter" data-level="24.5.4" data-path="machine-learning.html"><a href="machine-learning.html#example-4-comparative-politics"><i class="fa fa-check"></i><b>24.5.4</b> Example 4: Comparative Politics</a></li>
<li class="chapter" data-level="24.5.5" data-path="machine-learning.html"><a href="machine-learning.html#example-5-peace-and-conflict"><i class="fa fa-check"></i><b>24.5.5</b> Example 5: Peace and Conflict</a></li>
<li class="chapter" data-level="24.5.6" data-path="machine-learning.html"><a href="machine-learning.html#example-6-international-relations"><i class="fa fa-check"></i><b>24.5.6</b> Example 6: International Relations</a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="machine-learning.html"><a href="machine-learning.html#advantages-of-method-5"><i class="fa fa-check"></i><b>24.6</b> Advantages of Method</a></li>
<li class="chapter" data-level="24.7" data-path="machine-learning.html"><a href="machine-learning.html#disadvantages-of-method-3"><i class="fa fa-check"></i><b>24.7</b> Disadvantages of Method</a></li>
<li class="chapter" data-level="24.8" data-path="machine-learning.html"><a href="machine-learning.html#broader-significanceuse-in-political-science-6"><i class="fa fa-check"></i><b>24.8</b> Broader significance/use in political science</a></li>
<li class="chapter" data-level="24.9" data-path="machine-learning.html"><a href="machine-learning.html#conclusion-8"><i class="fa fa-check"></i><b>24.9</b> Conclusion</a></li>
<li class="chapter" data-level="24.10" data-path="machine-learning.html"><a href="machine-learning.html#application-questions-10"><i class="fa fa-check"></i><b>24.10</b> Application Questions</a></li>
<li class="chapter" data-level="24.11" data-path="machine-learning.html"><a href="machine-learning.html#key-terms-9"><i class="fa fa-check"></i><b>24.11</b> Key Terms</a></li>
<li class="chapter" data-level="24.12" data-path="machine-learning.html"><a href="machine-learning.html#answers-to-application-questions-9"><i class="fa fa-check"></i><b>24.12</b> Answers to Application Questions</a></li>
<li class="chapter" data-level="24.13" data-path="machine-learning.html"><a href="machine-learning.html#manual-bibliography---for-checking"><i class="fa fa-check"></i><b>24.13</b> Manual bibliography - for checking</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i><b>25</b> Conclusions</a></li>
<li class="divider"></li>
<li><a href="https://www.library.northwestern.edu/research/scholarly/index.html" target="_blank">Published by Northwestern University Libraries</a> using <a href="https://github.com/rstudio/bookdown" target="blank">Bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Empirical Methods in Political Science: An Introduction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="conclusions" class="section level1">
<h1><span class="header-section-number">25</span> Conclusions</h1>
<p><strong>By Jean Clipperton</strong></p>
<p>Throughout the text, we’ve worked to explain the different elements of social science and how they help us build, develop, and test theories about the world.</p>

<div id="refs" class="references">
<div>
<p>Acemoglu, Daron, Suresh Naidu, Pascual Restrepo, and James A Robinson. 2019. “Democracy Does Cause Growth.” <em>Journal of Political Economy</em> 127 (1). University of Chicago Press Chicago, IL: 47–100.</p>
</div>
<div>
<p>Alesina, Alberto, Edward Glaeser, and Bruce Sacerdote. 2001. “Why Doesn’t the Us Have a European-Style Welfare System?” National bureau of economic research.</p>
</div>
<div>
<p>Amrhein, Valentin, Sander Greenland, and Blake McShane. 2019. “Scientists Rise up Against Statistical Significance.” <em>Nature</em> 567. Nature Publishing Group: 305–7.</p>
</div>
<div>
<p>Angrist, Joshua David, and Jörn-Steffen Pischke. 2015. <em>Mastering ’Metrics: The Path from Cause to Effect</em>. Princeton ; Oxford: Princeton University Press.</p>
</div>
<div>
<p>Angrist, Joshua D., and Victor Lavy. 1999. “Using Maimonides’ Rule to Estimate the Effect of Class Size on Scholastic Achievement.” <em>The Quarterly Journal of Economics</em> 114 (2): 533–75. <a href="https://doi.org/10.1162/003355399556061">https://doi.org/10.1162/003355399556061</a>.</p>
</div>
<div>
<p>Angrist, Joshua D, Victor Lavy, Jetson Leder-Luis, and Adi Shany. 2017. “Maimonides Rule Redux.” Working Paper 23486. National Bureau of Economic Research. <a href="https://doi.org/10.3386/w23486">https://doi.org/10.3386/w23486</a>.</p>
</div>
<div>
<p>Ansolabehere, Stephen, and Brian F Schaffner. 2014. “Does Survey Mode Still Matter? Findings from a 2010 Multi-Mode Comparison.” <em>Political Analysis</em> 22 (3). Cambridge University Press: 285–303.</p>
</div>
<div>
<p>Bacharach, Samuel B. 1989. “Organizational Theories: Some Criteria for Evaluation.” <em>Academy of Management Review</em> 14 (4): 496–515.</p>
</div>
<div>
<p>Barakso, Maryann, Daniel M Sabet, and Brian Schaffner. 2013. <em>Understanding Political Science Research Methods: The Challenge of Inference</em>. Routledge.</p>
</div>
<div>
<p>Bennett, Andre, Aharo Barth, and Kennet R Rutherford. 2003. “Do We Preach What We Practice? A Survey of Methods in Political Science Journals and Curricula.” <em>PS: Political Science &amp; Politics</em> 36 (3): 373–78.</p>
</div>
<div>
<p>Blaydes, Lisa, Justin Grimmer, and Alison McQueen. 2018. “Mirrors for Princes and Sultans: Advice on the Art of Governance in the Medieval Christian and Islamic Worlds.” <em><span style="font-style:normal;">Journal of Politics</span></em> 80 (4): 1150–67.</p>
</div>
<div>
<p>Boigelot, Denis. 2011. “An Example of the Correlation of X and Y for Various Distributions of (X,y) Pairs.” Wikimedia Commons.</p>
</div>
<div>
<p>Boix, Carles, and Susan C Stokes. 2003. “Endogenous Democratization.” <em>World Politics</em> 55 (4). Cambridge University Press: 517–49.</p>
</div>
<div>
<p>Bonilla, Tabitha, and Cecilia Hyunjung Mo. 2018. “Bridging the Partisan Divide on Immigration Policy Attitudes Through a Bipartisan Issue Area: The Case of Human Trafficking.” <em>Journal of Experimental Political Science</em> 5 (2). Cambridge University Press: 107–20. <a href="https://doi.org/10.1017/XPS.2018.3">https://doi.org/10.1017/XPS.2018.3</a>.</p>
</div>
<div>
<p>Booth, Andrew, Anthea Sutton, and Diana Papaioannou. 2016. <em>Systematic Approaches to a Successful Literature Review</em>. SAGE.</p>
</div>
<div>
<p>Borell-Porta, Mireia, Joan Costa- Font, and Julia Phillip. 2018. “The ’Mighty Girl’ Effect: Does Parenting Daughters Alter Attitudes Towards Gender Roles?” <em>IZA Institute of Labor Economics</em> DP N. 11259.</p>
</div>
<div>
<p>Bouka, Yolande. 2013. “(Oral) History of Violence: Conflicting Narratives in Post-Genocide Rwanda.” <em>Oral History Forum</em> 33.</p>
</div>
<div>
<p>Broockman, David, Joshua Kalla, and Peter Aronow. 2015. “Irregularities in LaCour (2014).”</p>
</div>
<div>
<p>Bullock, John G., and Shang E. Ha. 2011. “Mediation Analysis Is Harder Than It Looks.” In <em>Cambridge Handbook of Experimental Political Science</em>, edited by James N. Druckman, Donald P. Green, James H. Kuklinski, and Arthur Lupia, 508–22. Cambridge: Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511921452.035">https://doi.org/10.1017/CBO9780511921452.035</a>.</p>
</div>
<div>
<p>Cantú, Francisco, and Sebastián M. Saiegh. 2011. “Fraudulent Democracy? An Analysis of Argentina’s Infamous Decade Using Supervised Machine Learning.” <em><span style="font-style:normal;">Political Analysis</span></em> 19 (4): 409–33.</p>
</div>
<div>
<p>Carroll, Robert J., and Brenton Kenkel. 2019. “Prediction.” <em>Proxies, and Power. <span style="font-style:normal;">American Journal of Political Science</span></em>.</p>
</div>
<div>
<p>Chen, Dingding, Chao-yo Cheng, and Johannes Urpelainen. 2016. “Support for Renewable Energy in China: A Survey Experiment with Internet Users.” <em>Journal of Cleaner Production</em> 112 (January): 3750–8. <a href="https://doi.org/10.1016/j.jclepro.2015.08.109">https://doi.org/10.1016/j.jclepro.2015.08.109</a>.</p>
</div>
<div>
<p>Clark, William Roberts, Matt Golder, and Sona Nadenichek Golder. 2013. <em>Principles of Comparative Politics</em>. Los Angeles, CA: SAGE Publications.</p>
</div>
<div>
<p>Coe, Kevin, David Tewksbury, Bradley J. Bond, Kristin L. Drogos, Robert W. Porter, Ashley Yahn, and Yuanyuan Zhang. 2008. “Hostile News: Partisan Use and Perceptions of Cable News Programming.” <em>Journal of Communication</em> 58 (2): 201–19. <a href="https://doi.org/10.1111/j.1460-2466.2008.00381.x">https://doi.org/10.1111/j.1460-2466.2008.00381.x</a>.</p>
</div>
<div>
<p>Cohen, Cathy J. 1999. <em>The Boundaries of Blackness: AIDS and the Breakdown of Black Politics</em>. Chicago; London: The University of Chicago Press.</p>
</div>
<div>
<p>Collier, David, and John Gerring, eds. 2009. <em>Concepts and Method in Social Science: The Tradition of Giovanni Sartori</em>. New York: Routledge.</p>
</div>
<div>
<p>Cook, Kathleen E., and Elise Murowchick. 2014. “Do Literature Review Skills Transfer from One Course to Another?” <em>Psychology Learning &amp; Teaching</em> 13 (1): 3–11. <a href="https://doi.org/10.2304/plat.2014.13.1.3">https://doi.org/10.2304/plat.2014.13.1.3</a>.</p>
</div>
<div>
<p>Dawson, Michael C. 2001. <em>Black Visions: The Roots and Contemporary African-American Political Ideologies</em>. Chicago; London: The University of Chicago Press.</p>
</div>
<div>
<p>De La O, Ana L. 2013. “Do Conditional Cash Transfers Affect Electoral Behavior? Evidence from a Randomized Experiment in Mexico.” <em>American Journal of Political Science</em> 57 (1): 1–14.</p>
</div>
<div>
<p>Dionne, Kim Yi, and Jeremy Horowitz. 2016. “The Political Effects of Agricultural Subsidies in Africa: Evidence from Malawi.” <em>World Development</em> 87 (November): 215–26. <a href="https://doi.org/10.1016/j.worlddev.2016.06.011">https://doi.org/10.1016/j.worlddev.2016.06.011</a>.</p>
</div>
<div>
<p>Duverger, Maurice. 1954. <em>Political Parties: Their Organization and Activity in the Modern State</em>. New York, NY: Wiley.</p>
</div>
<div>
<p>Emerson, Robert M., Rachel I. Fretz, and Linda L. Shaw. 2011. <em>Writing Ethnographic Fieldnotes. Second</em>. Chicago; London: The University of Chicago Press.</p>
</div>
<div>
<p>Erikson, Robert S, and Kent L Tedin. 2015. <em>American Public Opinion: Its Origins, Content and Impact</em>. Routledge.</p>
</div>
<div>
<p>Ferguson, Thomas, Benjamin Page, Jacob Rothschild, Arturo Chang, and Jie Chen. 2018. “The Economic and Social Roots of Populist Rebellion: Support for Donald Trump in 2016.” <em>Institute for New Economic Thinking Working Paper Series</em>, no. 83.</p>
</div>
<div>
<p>Ferree, Karen E. 2006. “Explaining South Africa’s Racial Census.” <em>The Journal of Politics</em> 68 (4): 803–15. <a href="https://doi.org/10.1111/j.1468-2508.2006.00471.x">https://doi.org/10.1111/j.1468-2508.2006.00471.x</a>.</p>
</div>
<div>
<p>Fink, Arlene. 2013. <em>Conducting Research Literature Reviews: From the Internet to Paper</em>. 4th ed. SAGE.</p>
</div>
<div>
<p>Fraile, Marta, and Irene Sánchez-Vítores. 2019. “Tracing the Gender Gap in Political Interest over the Life Span: A Panel Analysis.” <em>Political Psychology</em>, May. <a href="https://doi.org/10.1111/pops.12600">https://doi.org/10.1111/pops.12600</a>.</p>
</div>
<div>
<p>Frymer, Paul. 2017. <em>Building an American Empire: The Era of Territorial and Political Expansion</em>. Princeton; Oxford: Princeton University Press.</p>
</div>
<div>
<p>García-Rivero, Carlos. 2006. “Race, Class and Underlying Trends in Party Support in South Africa.” <em>Party Politics</em> 12 (1): 57–75. <a href="https://doi.org/10.1177/1354068806059344">https://doi.org/10.1177/1354068806059344</a>.</p>
</div>
<div>
<p>Goertz, Gary. 2006. <em>Social Science Concepts: A User’s Guide</em>. Princeton: Princeton University Press.</p>
</div>
<div>
<p>González, Yanilda M. 2017. “What Citizens Can See of the State: Police and the Construction of Democratic Citizenship in Latin America.” <em>Theoretical Criminology</em> 21 (4): 494–511.</p>
</div>
<div>
<p>Gosnell, Harold F. 1927. <em>Getting Out the Vote: An Experiment in the Stimulation of Voting</em>. The University of Chicago press.</p>
</div>
<div>
<p>Groves, Robert M. 2011. “Three Eras of Survey Research.” <em>Public Opinion Quarterly</em> 75 (5). Oxford University Press: 861–71.</p>
</div>
<div>
<p>Hadaway, C Kirk, Penny Long Marler, and Mark Chaves. 1993. “What the Polls Don’t Show: A Closer Look at Us Church Attendance.” <em>American Sociological Review</em>. JSTOR, 741–52.</p>
</div>
<div>
<p>Hainmueller, Jens, Dominik Hangartner, and Teppei Yamamoto. 2015. “Validating Vignette and Conjoint Survey Experiments Against Real-World Behavior.” <em>Proceedings of the National Academy of Sciences</em> 112 (8): 2395–2400. <a href="https://doi.org/10.1073/pnas.1416587112">https://doi.org/10.1073/pnas.1416587112</a>.</p>
</div>
<div>
<p>Hainmueller, Jens, and Michael J Hiscox. 2006. “Learning to Love Globalization: Education and Individual Attitudes Toward International Trade.” <em>International Organization</em> 60 (2). Cambridge University Press: 469–98.</p>
</div>
<div>
<p>Harris-Perry, Melissa V. 2011. <em>Sister Citizen: Shame, Stereotypes, and Black Women in America. New Haven and</em>. London: Yale University Press.</p>
</div>
<div>
<p>Hart, Chris. 1998. <em>Doing a Literature Review: Releasing the Social Science Research Imagination</em>. Thousand Oaks, CA: SAGE Publications.</p>
</div>
<div>
<p>Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. <em><span style="font-style:normal;">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</span></em>. 2nd ed. New York City: Springer.</p>
</div>
<div>
<p>Helmke, Gretchen. 2005. <em>Courts Under Constraints: Judges, Generals, and Presidents in Argentina</em>. Cambridge: Cambridge University Press.</p>
</div>
<div>
<p>Higgins, George E, Shaun L Gabbidon, and Favian Martin. 2010. “The Role of Race/Ethnicity and Race Relations on Public Opinion Related to the Immigration and Crime Link.” <em>Journal of Criminal Justice</em> 38 (1). Elsevier: 51–56.</p>
</div>
<div>
<p>Hochschild, Jennifer L., Vesla Weaver, and Traci D. Burch. 2012. <em>Creating a New Racial Order: How Immigration, Multiracialism, Genomics, and the Young Can Remake Race in America</em>. Princeton; Oxford: Princeton University Press.</p>
</div>
<div>
<p>Hopkins, Daniel J., and Jonathan M. Ladd. 2014. “The Consequences of Broader Media Choice: Evidence from the Expansion of Fox News.” <em>Quarterly Journal of Political Science</em> 9 (1): 115–35. <a href="https://doi.org/10.1561/100.00012099">https://doi.org/10.1561/100.00012099</a>.</p>
</div>
<div>
<p>Iyengar, Shanto, Mark D. Peters, and Donald R. Kinder. 1982. “Experimental Demonstrations of the ‘Not-so-Minimal’ Consequences of Television News Programs.” <em>American Political Science Review</em> 76 (4): 848–58. <a href="https://doi.org/10.1017/S000305540018966X">https://doi.org/10.1017/S000305540018966X</a>.</p>
</div>
<div>
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em><span style="font-style:normal;">An Introduction to Statistical Learning: With Applications in R</span></em>. 7th ed. New York City: Springer.</p>
</div>
<div>
<p>Jamison, Julian C. 2019. “The Entry of Randomized Assignment into the Social Sciences.” <em>Journal of Causal Inference</em> 7 (1). <a href="https://doi.org/10.1515/jci-2017-0025">https://doi.org/10.1515/jci-2017-0025</a>.</p>
</div>
<div>
<p>Jesson, Jill, Lydia Matheson, and Fiona M. Lacey. 2011. <em>Doing Your Literature Review: Traditional and Systematic Techniques</em>. Thousand Oaks, CA: SAGE.</p>
</div>
<div>
<p>Johnson, Janet Buttolph, H. T. Reynolds, and Jason D. Mycoff. 2016. <em>Political Science Research Methods</em>. 8th ed. Washington, DC: CQ Press.</p>
</div>
<div>
<p>Karl, Kristyn L. 2019. “Motivating Participation Through Political Ads: Comparing the Effects of Physiology and Self-Reported Emotion.” <em>Political Behavior</em>, September. <a href="https://doi.org/10.1007/s11109-019-09569-2">https://doi.org/10.1007/s11109-019-09569-2</a>.</p>
</div>
<div>
<p>Knopf, Jeffrey W. 2006. “Doing a Literature Review.” <em>PS: Political Science and Politics</em> 39 (1): 127–32.</p>
</div>
<div>
<p>Kramer, Katherine J. 2016. <em>The Politics of Resentment: Rural Consciousness in Wisconsin and the Rise of Scott Walker</em>. Chicago; London: The University of Chicago Press.</p>
</div>
<div>
<p>Kuenzi, Michelle, and Gina Lambright. 2005. “Party Systems and Democratic Consolidation in Africa’s Electoral Regimes.” <em>Party Politics</em> 11 (4): 423–46. <a href="https://doi.org/10.1177/1354068805053211">https://doi.org/10.1177/1354068805053211</a>.</p>
</div>
<div>
<p>Kuhn, Thomas S. 1996. <em>The Structure of Scientific Revolutions, 3rd Ed.</em> The Structure of Scientific Revolutions, 3rd Ed. Chicago, IL, US. <a href="https://doi.org/10.7208/chicago/9780226458106.001.0001">https://doi.org/10.7208/chicago/9780226458106.001.0001</a>.</p>
</div>
<div>
<p>Kuziemko, Ilyana, Jessica Pan, Jenny Shen, and Ebonya Washington. 2018. “The Mommy Effect: Do Women Anticipate the Employment Effects of Motherhood?” <em>NBER Working Paper Series</em> N. 24740.</p>
</div>
<div>
<p>Lee, Stephanie M. 2018. “Sliced and Diced: The Inside Story of How an Ivy League Food Scientist Turned Shoddy Data into Viral Studies.” <em>BuzzFeed News</em>. https://www.buzzfeednews.com/article/stephaniemlee/brian-wansink-cornell-p-hacking.</p>
</div>
<div>
<p>Lipset, Seymour Martin. 1959. “Some Social Requisites of Democracy: Economic Development and Political Legitimacy.” <em>American Political Science Review</em> 53 (01): 69–105. <a href="https://doi.org/10.2307/1951731">https://doi.org/10.2307/1951731</a>.</p>
</div>
<div>
<p>Lombard, Matthew, Jennifer Snyder-Duch, and Cheryl Campanella Bracken. 2002. “Content Analysis in Mass Communication: Assessment and Reporting of Intercoder Reliability.” <em>Human Communication Research</em> 28 (4). Wiley Online Library: 587–604.</p>
</div>
<div>
<p>Luo, Zhaotian, and Adam Przeworski. 2019. “Why Are the Fastest Growing Countries Autocracies?” <em>The Journal of Politics</em> 81 (2). The University of Chicago Press Chicago, IL: 663–69.</p>
</div>
<div>
<p>Mahoney, James, and Kathleen Thelen. 2009. <em>Explaining Institutional Change: Ambiguity, Agency, and Power</em>. Cambridge University Press.</p>
</div>
<div>
<p>Marion Suiseeya, Kimberly R., and Laura Zanotti. 2019. “Making Influence Visible: Innovating Ethnography at the Paris Climate Summit.” <em>Global Environmental Politics</em> 19 (2): 38–60. <a href="https://doi.org/10.1162/glep_a_00507">https://doi.org/10.1162/glep_a_00507</a>.</p>
</div>
<div>
<p>Masuoka, Natalie, and Jane Junn. 2013. <em>The Politics of Belonging: Race, Public Opinion, and Immigration</em>. University of Chicago Press.</p>
</div>
<div>
<p>Matejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics Through Simulated Annealing.” In <em>CHI 2017 Conference Proceedings:</em></p>
</div>
<div>
<p>Mayda, Anna Maria, Kevin H O’Rourke, and Richard Sinnott. 2007. “Risk, Government and Globalization: International Survey Evidence.” National Bureau of Economic Research.</p>
</div>
<div>
<p>Mazzocchi, Mario, Silvia Cagnone, Tino Bech-Larsen, Barbara Niedźwiedzka, Anna Saba, Bhavani Shankar, Wim Verbeke, and W Bruce Traill. 2015. “What Is the Public Appetite for Healthy Eating Policies? Evidence from a Cross-European Survey.” <em>Health Economics, Policy and Law</em> 10 (3). Cambridge University Press: 267–92.</p>
</div>
<div>
<p>Mengel, Friederike, Jan Sauermann, and Ulf Zölitz. 2019. “Gender Bias in Teaching Evaluations.” <em>Journal of the European Economic Association</em> 17 (2): 535–66. <a href="https://doi.org/10.1093/jeea/jvx057">https://doi.org/10.1093/jeea/jvx057</a>.</p>
</div>
<div>
<p>Mitchell, Tom. 1997. <em><span style="font-style:normal;">Machine Learning</span></em>. New York City: McGraw-Hill Education.</p>
</div>
<div>
<p>Moore, Barrington. 1966. <em>Social Origins of Dictatorship and Democracy: Lord and Peasant in the Making of the Modern World</em>. Boston, MA: Beacon Press.</p>
</div>
<div>
<p>Mueller, Hannes F., and Christopher Rauh. 2018. “Reading Between the Lines: Prediction of Political Violence.” <em>Using Newspaper Text. <span style="font-style:normal;">American Political Science Review</span></em> 112 (2): 358–75.</p>
</div>
<div>
<p>Munck, Gerardo L. 2009. <em>Measuring Democracy: A Bridge Between Scholarship and Politics</em>. Baltimore: Johns Hopkins University Press.</p>
</div>
<div>
<p>Ng, Andrew. n.d. <em><span style="font-style:normal;">Machine Learning</span></em>. Stanford University: Coursera. <a href="https://www.coursera.org/learn/">https://www.coursera.org/learn/</a>.</p>
</div>
<div>
<p>Olson, Mancur. 1965. <em>The Logic of Collective Action: Public Goods and the Theory of Groups</em>. Harvard Economic Studies 124. Cambridge, MA: Harvard University Press.</p>
</div>
<div>
<p>Onwuegbuzie, Anthony J., and Rebecca Frels. 2016. <em>Seven Steps to a Comprehensive Literature Review: A Multimodal and Cultural Approach</em>. Thousand Oaks, CA: SAGE.</p>
</div>
<div>
<p>Ostrom, Elinor. 2015. <em>Governing the Commons: The Evolution of Institutions for Collective Action</em>. Canto Classics. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9781316423936">https://doi.org/10.1017/CBO9781316423936</a>.</p>
</div>
<div>
<p>Pan, Jennifer, and Yiqing Xu. 2018. “China’s Ideological Spectrum.” <em>The Journal of Politics</em> 80 (1): 254–73. <a href="https://doi.org/10.1086/694255">https://doi.org/10.1086/694255</a>.</p>
</div>
<div>
<p>Parthasarathy, Ramya, Vijayendra Rao, and Nethra Palaniswamy. 2019. “Deliberative Democracy in an Unequal World: A Text-as-Data Study of South India’s Village Assemblies.” <em><span style="font-style:normal;">American Political Science Review</span></em> 113 (3): 623–40.</p>
</div>
<div>
<p>Pattillo, Mary. 2013. <em>Black Picket Fences: Privilege and Peril Among the Black Middle Class</em>. Chicago; London: The University of Chicago Press.</p>
</div>
<div>
<p>Paxton, Pamela. 2000. “Women’s Suffrage in the Measurement of Democracy: Problems of Operationalization.” <em>Studies in Comparative International Development</em> 35 (3): 92–111.</p>
</div>
<div>
<p>Pearlman, Wendy. 2017. <em>We Crossed a Bridge and It Trembled: Voices from Syria</em>. New York: HarperCollins.</p>
</div>
<div>
<p>Pond, Amy. 2017. “Economic Sanctions and Demand for Protection.” <em>Journal of Conflict Resolution</em> 61 (5): 1073–94. <a href="https://doi.org/10.1177/0022002715596777">https://doi.org/10.1177/0022002715596777</a>.</p>
</div>
<div>
<p>Price, Paul C, Rajiv Jhangiani, I-Chant A Chiang, and others. 2015. <em>Research Methods in Psychology</em>. BCCampus.</p>
</div>
<div>
<p>Rice, John. 2007. <em>Mathematical Statistics and Data Analysis</em>. Belmont, CA: Thompson/Brooks/Cole.</p>
</div>
<div>
<p>Ridley, Diana. 2012. <em>The Literature Review: A Step-by-Step Guide for Students</em>. 2nd ed. Thousand Oaks, CA: SAGE.</p>
</div>
<div>
<p>Rogers, Reuel R. 2006. <em>Afro-Caribbean Immigrants and the Politics of Incorporation: Ethnicity, Exception, or Exit</em>. Cambridge, New York, Melbourne, Cape Town, Singapore,; Sao Paulo: Cambridge University Press.</p>
</div>
<div>
<p>Sartori, Giovanni. 1970. “Concept Misformation in Comparative Politics.” <em>American Political Science Review</em> 64 (4): 1033–53. <a href="https://doi.org/10.2307/1958356">https://doi.org/10.2307/1958356</a>.</p>
</div>
<div>
<p>Schroeder, Elizabeth, and Daniel F. Stone. 2015. “Fox News and Political Knowledge.” <em>Journal of Public Economics</em> 126 (June): 52–63. <a href="https://doi.org/10.1016/j.jpubeco.2015.03.009">https://doi.org/10.1016/j.jpubeco.2015.03.009</a>.</p>
</div>
<div>
<p>Schuman, Howard, and Stanley Presser. 1996. <em>Questions and Answers in Attitude Surveys: Experiments on Question Form, Wording, and Context</em>. Sage.</p>
</div>
<div>
<p>Scotto, Thomas J, Jason Reifler, David Hudson, and others. 2017. “We Spend How Much? Misperceptions, Innumeracy, and Support for the Foreign Aid in the United States and Great Britain.” <em>Journal of Experimental Political Science</em> 4 (2). Cambridge University Press: 119–28.</p>
</div>
<div>
<p>Seawright, Jason. 2010. “Regression- Based Inference: A Case Study in Failed Causal Assessment.” In <em>Rethinking Social Inquiry: Diverse Tools, Shared Standards</em>, 2nd ed. Rowman &amp; Littlefield Publishers, Inc.</p>
</div>
<div>
<p>———. 2016. <em>Multi-Method Social Science: Combining Qualitative and Quantitative Tools</em>. Strategies for Social Inquiry. Cambridge: Cambridge University Press.</p>
</div>
<div>
<p>Seawright, Jason, and John Gerring. 2008. “Case Selection Techniques in Case Study Research: A Menu of Qualitative and Quantitative Options.” <em>Political Research Quarterly</em> 61 (2). Sage Publications Sage CA: Los Angeles, CA: 294–308.</p>
</div>
<div>
<p>Shineman, Victoria Anne. 2018. “If You Mobilize Them, They Will Become Informed: Experimental Evidence That Information Acquisition Is Endogenous to Costs and Incentives to Participate.” <em>British Journal of Political Science; Cambridge</em> 48 (1): 189–211. <a href="https://doi.org/http://dx.doi.org.turing.library.northwestern.edu/10.1017/S0007123416000168">https://doi.org/http://dx.doi.org.turing.library.northwestern.edu/10.1017/S0007123416000168</a>.</p>
</div>
<div>
<p>Shoemaker, Pamela J., James William Tankard Jr, and Dominic L. Lasorsa. 2003. <em>How to Build Social Science Theories</em>. Thousand Oaks, CA: SAGE Publications.</p>
</div>
<div>
<p>Stuart, Gretchen S, and David A Grimes. 2009. “Social Desirability Bias in Family Planning Studies: A Neglected Problem.” <em>Contraception</em> 80 (2). Elsevier: 108–12.</p>
</div>
<div>
<p>Teele, Dawn, Joshua Kalla, and Frances Rosenbluth. 2018. “The Ties That Double Bind: Social Roles and Women’s Underrepresentation in Politics.” <em>American Political Science Review</em> 112 (3). Cambridge University Press: 525–41. <a href="https://doi.org/10.1017/S0003055418000217">https://doi.org/10.1017/S0003055418000217</a>.</p>
</div>
<div>
<p>Thurston, Chloe N. 2018. <em>At the Boundaries of Homeownership: Credit, Discrimination, and the American State</em>. New York; Melbourne: Cambridge University Press.</p>
</div>
<div>
<p>Vargas, Robert. 2016. <em>Wounded City: Violent Turf Wars in a Chicago Barrio</em>. Oxford University Press.</p>
</div>
<div>
<p>Weiss, Robert S. 1994. <em>Learning from Strangers: The Art and Method of Qualitative Interview Studies</em>. New York: Free Press.</p>
</div>
<div>
<p>Whitaker, Richard, and Philip Lynch. 2011. “Explaining Support for the UK Independence Party at the 2009 European Parliament Elections.” <em>Journal of Elections, Public Opinion and Parties</em> 21 (3). <a href="https://doi.org/10.1080/17457289.2011.588439">https://doi.org/10.1080/17457289.2011.588439</a>.</p>
</div>
<div>
<p>White, Ismail K., Chryl N. Laird, and Troy D. Allen. 2014. “Selling Out?: The Politics of Navigating Conflicts Between Racial Group Interest and Self-Interest.” <em>American Political Science Review</em> 108 (4): 783–800. <a href="https://doi.org/10.1017/S000305541400046X">https://doi.org/10.1017/S000305541400046X</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Here is a more detailed explanation of what is meant by this sentence. The squared difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is actually a continuous random variable. In statistical theory, a random variable is a variable whose value is the outcome of a random process. Recall that in the general case <span class="math inline">\(Y = f(X) + \epsilon\)</span>, where <span class="math inline">\(X\)</span> represents a set of predictors. Since <span class="math inline">\(Y\)</span> is the function of the random error component <span class="math inline">\(\epsilon\)</span>, <span class="math inline">\(Y\)</span> is by definition a random variable. Now, notice that since <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a function of the random variable <span class="math inline">\(Y\)</span>, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> must also be a random variable. In particular, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a continuous random variable, since it can theoretical take on an infinite number of possible (non-negative) values. We can think of the expected value of a random variable as being the weighted or “long-run” average of the random variable’s possible values. To simplify the notation, let <span class="math inline">\(W=(Y-\hat{Y})^{2}\)</span>. Formally, let’s assume that the random variable <span class="math inline">\(W\)</span> has a probability density function <span class="math inline">\(g(w)\)</span>, which determines the distribution of the probabilities associated with the possible values of <span class="math inline">\(W\)</span>. The lower-case <span class="math inline">\(w\)</span> represents specific possible values of the random variable <span class="math inline">\(W\)</span>. In this case, then <span class="math inline">\(E(W) = \int_{-\infty}^{\infty} wg(w) dw\)</span>.<a href="introduction-what-is-political-science.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Another way to think about bias is that it is the systematic part of the difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span>. When <span class="math inline">\(\hat{f}(.)\neq{f}(.)\)</span>, the observed difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is often correlated with the gap between the estimated function and the true function.<a href="introduction-what-is-political-science.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Examples of popular supervised learning methods for regression include the ordinary least squares (OLS) regression, penalized/shrinkage methods such as the ridge and lasso regressions, regression trees, and artificial neural networks (ANN).<a href="introduction-what-is-political-science.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Examples of popular supervised learning methods for classification include various implementations of the logistic regression (i.e., binary, ordinal, multinomial), k-nearest neighbor (KNN), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), support vector classifiers (SVC), support vector machines (SVM), classification trees, and artificial neural networks (ANNs).<a href="introduction-what-is-political-science.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>This entails creating <span class="math inline">\(B\)</span> bootstrap samples by sampling with replacement from the original training set (<span class="math inline">\(n_{1}\)</span>). A classification tree is fit using each sample, and then the trees are combined (Cutler et al. 2014). This method is superior to using a single decision tree, because a single decision tree is affected by high variance; in contrast, by averaging the predictions across many <span class="math inline">\(B\)</span> trees, the variance is reduced. The main tuning parameter for bagged trees is <span class="math inline">\(B\)</span>, the number of bootstrapped trees.<a href="introduction-what-is-political-science.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Here is a more detailed explanation of what is meant by this sentence. The squared difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is actually a continuous random variable. In statistical theory, a random variable is a variable whose value is the outcome of a random process. Recall that in the general case <span class="math inline">\(Y = f(X) + \epsilon\)</span>, where <span class="math inline">\(X\)</span> represents a set of predictors. Since <span class="math inline">\(Y\)</span> is the function of the random error component <span class="math inline">\(\epsilon\)</span>, <span class="math inline">\(Y\)</span> is by definition a random variable. Now, notice that since <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a function of the random variable <span class="math inline">\(Y\)</span>, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> must also be a random variable. In particular, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a continuous random variable, since it can theoretical take on an infinite number of possible (non-negative) values. We can think of the expected value of a random variable as being the weighted or “long-run” average of the random variable’s possible values. To simplify the notation, let <span class="math inline">\(W=(Y-\hat{Y})^{2}\)</span>. Formally, let’s assume that the random variable <span class="math inline">\(W\)</span> has a probability density function <span class="math inline">\(g(w)\)</span>, which determines the distribution of the probabilities associated with the possible values of <span class="math inline">\(W\)</span>. The lower-case <span class="math inline">\(w\)</span> represents specific possible values of the random variable <span class="math inline">\(W\)</span>. In this case, then <span class="math inline">\(E(W) = \int_{-\infty}^{\infty} wg(w) dw\)</span>.<a href="data.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Another way to think about bias is that it is the systematic part of the difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span>. When <span class="math inline">\(\hat{f}(.)\neq{f}(.)\)</span>, the observed difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is often correlated with the gap between the estimated function and the true function.<a href="data.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Examples of popular supervised learning methods for regression include the ordinary least squares (OLS) regression, penalized/shrinkage methods such as the ridge and lasso regressions, regression trees, and artificial neural networks (ANN).<a href="data.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>Here is a more detailed explanation of what is meant by this sentence. The squared difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is actually a continuous random variable. In statistical theory, a random variable is a variable whose value is the outcome of a random process. Recall that in the general case <span class="math inline">\(Y = f(X) + \epsilon\)</span>, where <span class="math inline">\(X\)</span> represents a set of predictors. Since <span class="math inline">\(Y\)</span> is the function of the random error component <span class="math inline">\(\epsilon\)</span>, <span class="math inline">\(Y\)</span> is by definition a random variable. Now, notice that since <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a function of the random variable <span class="math inline">\(Y\)</span>, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> must also be a random variable. In particular, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a continuous random variable, since it can theoretical take on an infinite number of possible (non-negative) values. We can think of the expected value of a random variable as being the weighted or “long-run” average of the random variable’s possible values. To simplify the notation, let <span class="math inline">\(W=(Y-\hat{Y})^{2}\)</span>. Formally, let’s assume that the random variable <span class="math inline">\(W\)</span> has a probability density function <span class="math inline">\(g(w)\)</span>, which determines the distribution of the probabilities associated with the possible values of <span class="math inline">\(W\)</span>. The lower-case <span class="math inline">\(w\)</span> represents specific possible values of the random variable <span class="math inline">\(W\)</span>. In this case, then <span class="math inline">\(E(W) = \int_{-\infty}^{\infty} wg(w) dw\)</span>.<a href="hypothesis.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Another way to think about bias is that it is the systematic part of the difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span>. When <span class="math inline">\(\hat{f}(.)\neq{f}(.)\)</span>, the observed difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is often correlated with the gap between the estimated function and the true function.<a href="hypothesis.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>Examples of popular supervised learning methods for regression include the ordinary least squares (OLS) regression, penalized/shrinkage methods such as the ridge and lasso regressions, regression trees, and artificial neural networks (ANN).<a href="hypothesis.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>Examples of popular supervised learning methods for classification include various implementations of the logistic regression (i.e., binary, ordinal, multinomial), k-nearest neighbor (KNN), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), support vector classifiers (SVC), support vector machines (SVM), classification trees, and artificial neural networks (ANNs).<a href="hypothesis.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>This entails creating <span class="math inline">\(B\)</span> bootstrap samples by sampling with replacement from the original training set (<span class="math inline">\(n_{1}\)</span>). A classification tree is fit using each sample, and then the trees are combined (Cutler et al. 2014). This method is superior to using a single decision tree, because a single decision tree is affected by high variance; in contrast, by averaging the predictions across many <span class="math inline">\(B\)</span> trees, the variance is reduced. The main tuning parameter for bagged trees is <span class="math inline">\(B\)</span>, the number of bootstrapped trees.<a href="hypothesis.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>Here is a more detailed explanation of what is meant by this sentence. The squared difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is actually a continuous random variable. In statistical theory, a random variable is a variable whose value is the outcome of a random process. Recall that in the general case <span class="math inline">\(Y = f(X) + \epsilon\)</span>, where <span class="math inline">\(X\)</span> represents a set of predictors. Since <span class="math inline">\(Y\)</span> is the function of the random error component <span class="math inline">\(\epsilon\)</span>, <span class="math inline">\(Y\)</span> is by definition a random variable. Now, notice that since <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a function of the random variable <span class="math inline">\(Y\)</span>, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> must also be a random variable. In particular, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a continuous random variable, since it can theoretical take on an infinite number of possible (non-negative) values. We can think of the expected value of a random variable as being the weighted or “long-run” average of the random variable’s possible values. To simplify the notation, let <span class="math inline">\(W=(Y-\hat{Y})^{2}\)</span>. Formally, let’s assume that the random variable <span class="math inline">\(W\)</span> has a probability density function <span class="math inline">\(g(w)\)</span>, which determines the distribution of the probabilities associated with the possible values of <span class="math inline">\(W\)</span>. The lower-case <span class="math inline">\(w\)</span> represents specific possible values of the random variable <span class="math inline">\(W\)</span>. In this case, then <span class="math inline">\(E(W) = \int_{-\infty}^{\infty} wg(w) dw\)</span>.<a href="surveys.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>Another way to think about bias is that it is the systematic part of the difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span>. When <span class="math inline">\(\hat{f}(.)\neq{f}(.)\)</span>, the observed difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is often correlated with the gap between the estimated function and the true function.<a href="surveys.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>Examples of popular supervised learning methods for regression include the ordinary least squares (OLS) regression, penalized/shrinkage methods such as the ridge and lasso regressions, regression trees, and artificial neural networks (ANN).<a href="surveys.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>Examples of popular supervised learning methods for classification include various implementations of the logistic regression (i.e., binary, ordinal, multinomial), k-nearest neighbor (KNN), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), support vector classifiers (SVC), support vector machines (SVM), classification trees, and artificial neural networks (ANNs).<a href="surveys.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>This entails creating <span class="math inline">\(B\)</span> bootstrap samples by sampling with replacement from the original training set (<span class="math inline">\(n_{1}\)</span>). A classification tree is fit using each sample, and then the trees are combined (Cutler et al. 2014). This method is superior to using a single decision tree, because a single decision tree is affected by high variance; in contrast, by averaging the predictions across many <span class="math inline">\(B\)</span> trees, the variance is reduced. The main tuning parameter for bagged trees is <span class="math inline">\(B\)</span>, the number of bootstrapped trees.<a href="surveys.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>This is the same as bagging, but now the model is only allowed to consider only a random subset <span class="math inline">\(m\)</span> of the <span class="math inline">\(p\)</span> predictors at each split (such that <span class="math inline">\(m \ll p\)</span>, e.g., <span class="math inline">\(n \approx \sqrt{p}\)</span>). The logic here is that by intentionally restricting the number of predictors that can be considered at each split, the trees will become less correlated (Cutler 2005). In many cases, decorrelating the <span class="math inline">\(B\)</span> trees in this way can lead to reduced test error.<a href="surveys.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>With boosted trees, the trees are grown sequentially: each tree is fit to the residuals from the previous model. The logic of this approach is that it allows each successive tree to address the weaknesses of the previous tree.<a href="surveys.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Here is a more detailed explanation of what is meant by this sentence. The squared difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is actually a continuous random variable. In statistical theory, a random variable is a variable whose value is the outcome of a random process. Recall that in the general case <span class="math inline">\(Y = f(X) + \epsilon\)</span>, where <span class="math inline">\(X\)</span> represents a set of predictors. Since <span class="math inline">\(Y\)</span> is the function of the random error component <span class="math inline">\(\epsilon\)</span>, <span class="math inline">\(Y\)</span> is by definition a random variable. Now, notice that since <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a function of the random variable <span class="math inline">\(Y\)</span>, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> must also be a random variable. In particular, <span class="math inline">\((Y-\hat{Y})^{2}\)</span> is a continuous random variable, since it can theoretical take on an infinite number of possible (non-negative) values. We can think of the expected value of a random variable as being the weighted or “long-run” average of the random variable’s possible values. To simplify the notation, let <span class="math inline">\(W=(Y-\hat{Y})^{2}\)</span>. Formally, let’s assume that the random variable <span class="math inline">\(W\)</span> has a probability density function <span class="math inline">\(g(w)\)</span>, which determines the distribution of the probabilities associated with the possible values of <span class="math inline">\(W\)</span>. The lower-case <span class="math inline">\(w\)</span> represents specific possible values of the random variable <span class="math inline">\(W\)</span>. In this case, then <span class="math inline">\(E(W) = \int_{-\infty}^{\infty} wg(w) dw\)</span>.<a href="machine-learning.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>Another way to think about bias is that it is the systematic part of the difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span>. When <span class="math inline">\(\hat{f}(.)\neq{f}(.)\)</span>, the observed difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{Y}\)</span> is often correlated with the gap between the estimated function and the true function.<a href="machine-learning.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>Examples of popular supervised learning methods for regression include the ordinary least squares (OLS) regression, penalized/shrinkage methods such as the ridge and lasso regressions, regression trees, and artificial neural networks (ANN).<a href="machine-learning.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>Examples of popular supervised learning methods for classification include various implementations of the logistic regression (i.e., binary, ordinal, multinomial), k-nearest neighbor (KNN), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), support vector classifiers (SVC), support vector machines (SVM), classification trees, and artificial neural networks (ANNs).<a href="machine-learning.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>This entails creating <span class="math inline">\(B\)</span> bootstrap samples by sampling with replacement from the original training set (<span class="math inline">\(n_{1}\)</span>). A classification tree is fit using each sample, and then the trees are combined (Cutler et al. 2014). This method is superior to using a single decision tree, because a single decision tree is affected by high variance; in contrast, by averaging the predictions across many <span class="math inline">\(B\)</span> trees, the variance is reduced. The main tuning parameter for bagged trees is <span class="math inline">\(B\)</span>, the number of bootstrapped trees.<a href="machine-learning.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>This is the same as bagging, but now the model is only allowed to consider only a random subset <span class="math inline">\(m\)</span> of the <span class="math inline">\(p\)</span> predictors at each split (such that <span class="math inline">\(m \ll p\)</span>, e.g., <span class="math inline">\(n \approx \sqrt{p}\)</span>). The logic here is that by intentionally restricting the number of predictors that can be considered at each split, the trees will become less correlated (Cutler 2005). In many cases, decorrelating the <span class="math inline">\(B\)</span> trees in this way can lead to reduced test error.<a href="machine-learning.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>With boosted trees, the trees are grown sequentially: each tree is fit to the residuals from the previous model. The logic of this approach is that it allows each successive tree to address the weaknesses of the previous tree.<a href="machine-learning.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>Root mean squared error (RMSE) is a measure of the average absolute difference between the predicted value of the outcome and the actual observed value. The smaller the RMSE, the more accurate the estimates of the outcome.<a href="machine-learning.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>Although this is a strong assumption, research has shown that NB algorithm is robust to minor deviations from independence of the features.<a href="machine-learning.html#fnref29" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="machine-learning.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
